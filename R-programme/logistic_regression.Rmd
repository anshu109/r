```{r}
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
```
# reading data

```{r}
titanic <- read.csv("train.csv")
```


# viewing data
```{r}
head(titanic)
```


# structure of the data
```{r}
str(titanic)

```

#Summary Statistics

```{r}
#library(Hmisc)
summary(titanic)
head(titanic)
str(titanic)
summary(titanic)

```

# 2-way contingency tables
```{r}
xtabs(~admit + prestige, data = titanic)
```


##############################################################################
# Outlier Detection

```{r}
sapply(titanic[,5:7], function(x) quantile(x, c(.01,.05,.25,.5,.75,.90,.95, .99, 1),na.rm=TRUE) )
```



##############################################################################
# Missing Value Imputation

```{r}
sapply(titanic, function(x) sum(is.na(x)) )
train_data$gre[is.na(titanic$gre)] <- mean(titanic$gre, na.rm=TRUE)

titanic2<-titanic

sapply(titanic2, function(x) titanic2[,x][is.na(titanic2[,x])]<- mean(titanic2[,x], na.rm=TRUE))
```

##############################################################################
# Correlation and VIF 

cor(train_data[,1:3])

library(usdm)
vif(train_data[,1:3])

##############################################################################
# Information Value 

library(plyr)
library(sqldf)
library(rpart)

source("C:\\xyz.R")

file.sources = list.files("others", full.names=TRUE)
sapply(file.sources,source,.GlobalEnv)

data <- train_data
data$admit <- factor(data$admit, levels= c("1","0"))
levels(data$admit)

str(data)
iv.mult(data, y="admit", vars=c("gre","gpa","prestige"), summary="TRUE")


##############################################################################
# Create training and validation sets 

set.seed(123)
smp_size <- floor(0.7 * nrow(train_data))

train_ind <- sample(seq_len(nrow(train_data)), size = smp_size)

training <- train_data[train_ind, ]
validation <- train_data[-train_ind, ]

##############################################################################
# Running the Logistic Model on Training set 

?lm
?describe
?glm

admit ~ gre + gpa + prestige

mylogit <- glm(admit ~ gre + gpa + prestige, data = training, family = "binomial")

mylogit2 <- glm(admit ~ gpa + prestige, data = training, family = "binomial")

summary(mylogit2)
# See how prestige has been used as a dummy variable

confint(mylogit, level=.90)

# Caluclating Concordance
# Refer to the blog here to see  about Concordance
# http://shashiasrblog.blogspot.in/2014/02/binary-logistic-regression-fast.html

fastConc<-function(model){
  # Get all actual observations and their fitted values into a frame
  fitted<-data.frame(cbind(model$y,model$fitted.values))
  colnames(fitted)<-c('respvar','score')
  # Subset only ones
  ones<-fitted[fitted[,1]==1,]
  # Subset only zeros
  zeros<-fitted[fitted[,1]==0,]
  
  # Initialise all the values
  pairs_tested<-nrow(ones)*nrow(zeros)
  conc<-0
  disc<-0
  
  # Get the values in a for-loop
  for(i in 1:nrow(ones))
  {
    conc<-conc + sum(ones[i,"score"]>zeros[,"score"])
    disc<-disc + sum(ones[i,"score"]<zeros[,"score"])
  }
  # Calculate concordance, discordance and ties
  concordance<-conc/pairs_tested
  discordance<-disc/pairs_tested
  ties_perc<-(1-concordance-discordance)
  return(list("Concordance"=concordance,
              "Discordance"=discordance,
              "Tied"=ties_perc,
              "Pairs"=pairs_tested))
}


fastConc(mylogit)
##############################################################################
#Check Performance on the Validation Set 

val <-predict(mylogit, validation, type="response") 

mydf <-cbind(validation,val)

mydf$response <- as.factor(ifelse(mydf$val>0.5, 1, 0))


library(ROCR)
logit_scores <- prediction(predictions=mydf$val, labels=mydf$admit)


#PLOT ROC CURVE
logit_perf <- performance(logit_scores, "tpr", "fpr")
plot(logit_perf,col = "darkblue",lwd=2,xaxs="i",yaxs="i",tck=NA, main="ROC Curve")
box()
abline(0,1, lty = 300, col = "green")
grid(col="aquamarine")


### AREA UNDER THE CURVE
logit_auc <- performance(logit_scores, "auc")
as.numeric(logit_auc@y.values)  ##AUC Value


#CONFUSION MATRIX
library(caret)
confusionMatrix(mydf$response,mydf$admit)


### KS STATISTIC
logit_ks <- max(logit_perf@y.values[[1]]-logit_perf@x.values[[1]])
logit_ks


## LIFT CHART
lift.obj <- performance(logit_scores, measure="lift", x.measure="rpp")
plot(lift.obj,
     main="Lift Chart",
     xlab="% Populations",
     ylab="Lift",
     col="blue")
abline(1,0,col="grey")


#GAINS TABLE
#install.packages("gains")
library(gains)
# gains table
gains.cross <- gains(actual=mydf$admit , predicted=mydf$val, groups=10)
print(gains.cross)

##############################################################################
#Scoring the Test Data using the model we just created 

pred <- predict(mylogit, test_data, type="response") 
final <- cbind(test_data,pred)

write.csv(final,"final_probs.csv")

##############################################################################
